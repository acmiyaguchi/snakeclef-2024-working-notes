\documentclass[]{style/ceurart}
\sloppy

\usepackage{listings}
\lstset{breaklines=true}

\begin{document}

\copyrightyear{2024}
\copyrightclause{Copyright for this paper by its authors.
  Use permitted under Creative Commons License Attribution 4.0
  International (CC BY 4.0).}

\conference{CLEF 2024: Conference and Labs of the Evaluation Forum, September 9-12, 2023, Grenoble, France}

\title{DS@GT-CLEF: DinoV2 Transfer Learning for Snake Identification}

\author[1]{Anthony Miyaguchi}[
orcid=0000-0002-9165-8718,
email=acmiyaguchi@gatech.edu,
]
\cormark[1]
\author[1]{Murilo Gustineli}[
email=murilogustineli@gatech.edu,
]
\cormark[1]
\author[1]{Austin Fischer}[
email=afischer39@gatech.edu,
]
\author[1]{Ryan Lundqvist}[
email=rlundqvist@gatech.edu,
]

\address[1]{Georgia Institute of Technology, North Ave NW, Atlanta, GA 30332}
\cortext[1]{Corresponding author.}


\begin{abstract}
    This is the abstract of the paper. 
    It should be a brief summary of the contents of the paper.
\end{abstract}

\begin{keywords}
  LaTeX class \sep
  paper template \sep
  paper formatting \sep
  CEUR-WS
\end{keywords}


\maketitle

\section{Introduction}

Introduction to the problem and the approach.

\section{Related Work}

Overview of related work.

\section{Methodology}

We built a pipeline to train a classification model to identify snakes using the dinov2 \cite{oquab2023dinov2} as the main feature extractor.
The pipeline comprises pre-processing, training, and inference stages implemented in separate modules to facilitate the development and testing of the model.

Preprocessing includes joining metadata and images into a columnar data store to help aid with data processing in a map-reduce setting.
We precompute the dinov2 embeddings for each image and extract the CLS token and a compressed version of the tile tokens using a 2D discrete cosine transform (DCT).
Transfer-learning tasks often use the CLS token from vision transformers (ViTs) to train classifiers on domain-specific tasks [citation needed].
We also keep coefficients from the DCT as an alternative representation of the image embeddings that are cheap to compute and store.
We use Apache Spark to process the images and metadata into a Parquet dataset comprised of 200 partitions.
We use the HuggingFace Transformers library to extract the embeddings from the dinov2 model in parallel using PySpark on a single g2-standard-8 machine on Google Cloud Platform (GCP) using an NVIDIA Tesla L4 GPU.

The training module uses the embeddings and metadata to train a classifier.
We train a neural network with a single linear layer in the same shape as the dinov2 embedding output (768 dimensions) without an activation function.
We experiment with negative log-likelihood loss for classification and the asymmetric loss function proposed by \cite{ridnik2021asymmetric} to account for class imbalance.

The inference module uses the trained model to make predictions on new images.
We build a script to run offline without access to the network (including local-loopback).
We chain the embedding extraction and model predictions and take the argmax of the output to get the predicted class.
Each observation instance may have multiple images, so we use the mode of the predictions using the first image as tie-breaker as the final prediction.

\section{Results}

% https://huggingface.co/spaces/BVRA/SnakeCLEF2024
% TODO: convert to a table
\begin{verbatim}
rank 	id 	Track1 	Track2 	F1 	Accuracy 	submission_datetime
1 	upupup 	85.63 	687 	43.66 	72.04 	2024-05-23 20:02:18
7 	Baseline with Swin-v2 tiny. 256x256. 	67.01 	1861 	13.34 	39.88 	2024-02-28 08:13:33
15 	DS@GT-LifeCLEF 	39.69 	3790 	0 	0 	2024-05-24 21:03:59
\end{verbatim}

We achieved a score of 39.7 on the main track, which is significantly lower than the top score of 85.6 and the baseline score of 67.0.

\section{Discussion}

While our score did not perform as well as the top score, we believe our approach has potential.
Our pipeline is the simplest possible implementation of the dinov2 model for snake identification and can be improved in many ways.

\section{Future Work}

What would you do next?

\section{Conclusions}

Summary of the work and its contributions.

\section*{Acknowledgements}

Thank you to the DS@GT CLEF team for their support.

\bibliography{main}

% \appendix
% \section{Online Resources}

\end{document}